{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "066bfb34",
   "metadata": {},
   "source": [
    "# 임포트하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84687471",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorflow) (3.2.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorflow) (0.24.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: libclang>=9.0.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorflow) (58.0.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.3)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorflow) (1.44.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.6.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19758bf1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipykernel in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (6.4.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from ipykernel) (0.1.2)\n",
      "Requirement already satisfied: jupyter-client<8.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from ipykernel) (6.1.12)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from ipykernel) (0.2.0)\n",
      "Requirement already satisfied: ipython<8.0,>=7.23.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from ipykernel) (7.29.0)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from ipykernel) (6.1)\n",
      "Requirement already satisfied: traitlets<6.0,>=4.1.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from ipykernel) (5.1.0)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from ipykernel) (1.4.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from ipython<8.0,>=7.23.1->ipykernel) (0.4.4)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from ipython<8.0,>=7.23.1->ipykernel) (58.0.4)\n",
      "Requirement already satisfied: decorator in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from ipython<8.0,>=7.23.1->ipykernel) (5.1.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from ipython<8.0,>=7.23.1->ipykernel) (0.18.0)\n",
      "Requirement already satisfied: pygments in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from ipython<8.0,>=7.23.1->ipykernel) (2.10.0)\n",
      "Requirement already satisfied: backcall in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from ipython<8.0,>=7.23.1->ipykernel) (0.2.0)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from ipython<8.0,>=7.23.1->ipykernel) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from ipython<8.0,>=7.23.1->ipykernel) (3.0.20)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython<8.0,>=7.23.1->ipykernel) (0.8.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from jupyter-client<8.0->ipykernel) (2.8.2)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from jupyter-client<8.0->ipykernel) (22.2.1)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from jupyter-client<8.0->ipykernel) (4.8.1)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from jupyter-core>=4.6.0->jupyter-client<8.0->ipykernel) (228)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8.0,>=7.23.1->ipykernel) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\smhrd\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->jupyter-client<8.0->ipykernel) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install ipykernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1152c0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "tf.compat.v1.random.set_random_seed(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a90493b",
   "metadata": {},
   "source": [
    "# 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b1c77a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('./data/영유아키.csv' , encoding=\"utf-8\")\n",
    "test=pd.read_csv('./data/테스트.csv' , encoding='euc-kr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa6b23a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, pd.get_dummies(train['성별'])], axis = 1)\n",
    "test = pd.concat([test, pd.get_dummies(test['성별'])], axis = 1)\n",
    "del train['성별']\n",
    "del test['성별']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23e7181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 부모키 삽입하기\n",
    "# pd.concat 사용해서 train, test에 부모키 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab1978af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1~2개월</th>\n",
       "      <th>2~3개월</th>\n",
       "      <th>3~4개월</th>\n",
       "      <th>4~5개월</th>\n",
       "      <th>5~6개월</th>\n",
       "      <th>6~7개월</th>\n",
       "      <th>7~8개월</th>\n",
       "      <th>8~9개월</th>\n",
       "      <th>9~10개월</th>\n",
       "      <th>10~11개월</th>\n",
       "      <th>...</th>\n",
       "      <th>12~15개월</th>\n",
       "      <th>15~18개월</th>\n",
       "      <th>18~21개월\\t</th>\n",
       "      <th>21~24개월\\t</th>\n",
       "      <th>2세</th>\n",
       "      <th>3세</th>\n",
       "      <th>4세</th>\n",
       "      <th>5세</th>\n",
       "      <th>남</th>\n",
       "      <th>여</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50.96</td>\n",
       "      <td>60.52</td>\n",
       "      <td>63.12</td>\n",
       "      <td>65.68</td>\n",
       "      <td>67.07</td>\n",
       "      <td>69.55</td>\n",
       "      <td>70.86</td>\n",
       "      <td>72.61</td>\n",
       "      <td>73.55</td>\n",
       "      <td>74.91</td>\n",
       "      <td>...</td>\n",
       "      <td>78.71</td>\n",
       "      <td>81.54</td>\n",
       "      <td>83.71</td>\n",
       "      <td>86.20</td>\n",
       "      <td>93.88</td>\n",
       "      <td>103.07</td>\n",
       "      <td>107.42</td>\n",
       "      <td>113.34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50.31</td>\n",
       "      <td>60.92</td>\n",
       "      <td>63.04</td>\n",
       "      <td>65.24</td>\n",
       "      <td>67.16</td>\n",
       "      <td>69.46</td>\n",
       "      <td>70.73</td>\n",
       "      <td>72.89</td>\n",
       "      <td>73.88</td>\n",
       "      <td>74.09</td>\n",
       "      <td>...</td>\n",
       "      <td>78.27</td>\n",
       "      <td>81.27</td>\n",
       "      <td>83.25</td>\n",
       "      <td>86.78</td>\n",
       "      <td>93.60</td>\n",
       "      <td>103.78</td>\n",
       "      <td>107.44</td>\n",
       "      <td>113.30</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50.37</td>\n",
       "      <td>60.84</td>\n",
       "      <td>63.27</td>\n",
       "      <td>65.39</td>\n",
       "      <td>67.68</td>\n",
       "      <td>69.54</td>\n",
       "      <td>70.02</td>\n",
       "      <td>72.78</td>\n",
       "      <td>73.88</td>\n",
       "      <td>74.57</td>\n",
       "      <td>...</td>\n",
       "      <td>78.01</td>\n",
       "      <td>81.35</td>\n",
       "      <td>83.10</td>\n",
       "      <td>86.66</td>\n",
       "      <td>93.67</td>\n",
       "      <td>103.47</td>\n",
       "      <td>107.39</td>\n",
       "      <td>113.60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.25</td>\n",
       "      <td>60.64</td>\n",
       "      <td>63.11</td>\n",
       "      <td>65.05</td>\n",
       "      <td>67.26</td>\n",
       "      <td>69.11</td>\n",
       "      <td>70.65</td>\n",
       "      <td>72.13</td>\n",
       "      <td>73.86</td>\n",
       "      <td>74.99</td>\n",
       "      <td>...</td>\n",
       "      <td>78.87</td>\n",
       "      <td>81.25</td>\n",
       "      <td>83.54</td>\n",
       "      <td>86.88</td>\n",
       "      <td>93.46</td>\n",
       "      <td>103.11</td>\n",
       "      <td>107.52</td>\n",
       "      <td>113.97</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50.53</td>\n",
       "      <td>60.70</td>\n",
       "      <td>63.24</td>\n",
       "      <td>65.90</td>\n",
       "      <td>67.55</td>\n",
       "      <td>69.21</td>\n",
       "      <td>70.05</td>\n",
       "      <td>72.75</td>\n",
       "      <td>73.32</td>\n",
       "      <td>74.74</td>\n",
       "      <td>...</td>\n",
       "      <td>78.23</td>\n",
       "      <td>81.16</td>\n",
       "      <td>83.55</td>\n",
       "      <td>86.60</td>\n",
       "      <td>93.32</td>\n",
       "      <td>103.85</td>\n",
       "      <td>107.69</td>\n",
       "      <td>113.15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>56.54</td>\n",
       "      <td>59.97</td>\n",
       "      <td>62.43</td>\n",
       "      <td>64.18</td>\n",
       "      <td>66.99</td>\n",
       "      <td>68.74</td>\n",
       "      <td>70.09</td>\n",
       "      <td>70.60</td>\n",
       "      <td>73.58</td>\n",
       "      <td>73.98</td>\n",
       "      <td>...</td>\n",
       "      <td>76.99</td>\n",
       "      <td>79.82</td>\n",
       "      <td>82.83</td>\n",
       "      <td>84.87</td>\n",
       "      <td>91.06</td>\n",
       "      <td>99.77</td>\n",
       "      <td>106.86</td>\n",
       "      <td>112.30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>56.17</td>\n",
       "      <td>59.01</td>\n",
       "      <td>62.59</td>\n",
       "      <td>64.28</td>\n",
       "      <td>66.43</td>\n",
       "      <td>68.46</td>\n",
       "      <td>70.24</td>\n",
       "      <td>70.50</td>\n",
       "      <td>73.31</td>\n",
       "      <td>73.91</td>\n",
       "      <td>...</td>\n",
       "      <td>76.05</td>\n",
       "      <td>79.87</td>\n",
       "      <td>82.97</td>\n",
       "      <td>84.73</td>\n",
       "      <td>91.15</td>\n",
       "      <td>99.98</td>\n",
       "      <td>106.66</td>\n",
       "      <td>112.90</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>56.70</td>\n",
       "      <td>59.55</td>\n",
       "      <td>62.83</td>\n",
       "      <td>64.96</td>\n",
       "      <td>66.43</td>\n",
       "      <td>68.21</td>\n",
       "      <td>70.08</td>\n",
       "      <td>70.76</td>\n",
       "      <td>73.99</td>\n",
       "      <td>73.99</td>\n",
       "      <td>...</td>\n",
       "      <td>76.75</td>\n",
       "      <td>79.28</td>\n",
       "      <td>82.90</td>\n",
       "      <td>84.04</td>\n",
       "      <td>91.32</td>\n",
       "      <td>99.87</td>\n",
       "      <td>106.11</td>\n",
       "      <td>112.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>56.47</td>\n",
       "      <td>59.62</td>\n",
       "      <td>62.89</td>\n",
       "      <td>64.95</td>\n",
       "      <td>66.89</td>\n",
       "      <td>68.77</td>\n",
       "      <td>71.00</td>\n",
       "      <td>70.44</td>\n",
       "      <td>73.48</td>\n",
       "      <td>73.57</td>\n",
       "      <td>...</td>\n",
       "      <td>76.71</td>\n",
       "      <td>79.96</td>\n",
       "      <td>82.83</td>\n",
       "      <td>84.45</td>\n",
       "      <td>91.91</td>\n",
       "      <td>99.32</td>\n",
       "      <td>106.82</td>\n",
       "      <td>112.38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>56.48</td>\n",
       "      <td>59.31</td>\n",
       "      <td>62.16</td>\n",
       "      <td>64.29</td>\n",
       "      <td>66.91</td>\n",
       "      <td>68.10</td>\n",
       "      <td>70.60</td>\n",
       "      <td>70.57</td>\n",
       "      <td>73.49</td>\n",
       "      <td>73.10</td>\n",
       "      <td>...</td>\n",
       "      <td>76.85</td>\n",
       "      <td>79.78</td>\n",
       "      <td>82.84</td>\n",
       "      <td>84.83</td>\n",
       "      <td>91.43</td>\n",
       "      <td>99.64</td>\n",
       "      <td>106.29</td>\n",
       "      <td>112.85</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1~2개월  2~3개월  3~4개월  4~5개월   5~6개월  6~7개월  7~8개월  8~9개월  9~10개월  \\\n",
       "0     50.96  60.52  63.12   65.68  67.07  69.55  70.86  72.61   73.55   \n",
       "1     50.31  60.92  63.04   65.24  67.16  69.46  70.73  72.89   73.88   \n",
       "2     50.37  60.84  63.27   65.39  67.68  69.54  70.02  72.78   73.88   \n",
       "3     50.25  60.64  63.11   65.05  67.26  69.11  70.65  72.13   73.86   \n",
       "4     50.53  60.70  63.24   65.90  67.55  69.21  70.05  72.75   73.32   \n",
       "...     ...    ...    ...     ...    ...    ...    ...    ...     ...   \n",
       "9995  56.54  59.97  62.43   64.18  66.99  68.74  70.09  70.60   73.58   \n",
       "9996  56.17  59.01  62.59   64.28  66.43  68.46  70.24  70.50   73.31   \n",
       "9997  56.70  59.55  62.83   64.96  66.43  68.21  70.08  70.76   73.99   \n",
       "9998  56.47  59.62  62.89   64.95  66.89  68.77  71.00  70.44   73.48   \n",
       "9999  56.48  59.31  62.16   64.29  66.91  68.10  70.60  70.57   73.49   \n",
       "\n",
       "      10~11개월  ...  12~15개월  15~18개월  18~21개월\\t  21~24개월\\t     2세      3세  \\\n",
       "0       74.91  ...    78.71    81.54      83.71      86.20  93.88  103.07   \n",
       "1       74.09  ...    78.27    81.27      83.25      86.78  93.60  103.78   \n",
       "2       74.57  ...    78.01    81.35      83.10      86.66  93.67  103.47   \n",
       "3       74.99  ...    78.87    81.25      83.54      86.88  93.46  103.11   \n",
       "4       74.74  ...    78.23    81.16      83.55      86.60  93.32  103.85   \n",
       "...       ...  ...      ...      ...        ...        ...    ...     ...   \n",
       "9995    73.98  ...    76.99    79.82      82.83      84.87  91.06   99.77   \n",
       "9996    73.91  ...    76.05    79.87      82.97      84.73  91.15   99.98   \n",
       "9997    73.99  ...    76.75    79.28      82.90      84.04  91.32   99.87   \n",
       "9998    73.57  ...    76.71    79.96      82.83      84.45  91.91   99.32   \n",
       "9999    73.10  ...    76.85    79.78      82.84      84.83  91.43   99.64   \n",
       "\n",
       "          4세      5세  남  여  \n",
       "0     107.42  113.34  1  0  \n",
       "1     107.44  113.30  1  0  \n",
       "2     107.39  113.60  1  0  \n",
       "3     107.52  113.97  1  0  \n",
       "4     107.69  113.15  1  0  \n",
       "...      ...     ... .. ..  \n",
       "9995  106.86  112.30  0  1  \n",
       "9996  106.66  112.90  0  1  \n",
       "9997  106.11  112.02  0  1  \n",
       "9998  106.82  112.38  0  1  \n",
       "9999  106.29  112.85  0  1  \n",
       "\n",
       "[10000 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06c511ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 부모키 추가시\n",
    "X_train = np.array(train.drop('5세',axis = 1))\n",
    "y_train = np.array(train.iloc[:,-5].copy())\n",
    "X_test = np.array(test.drop('5세',axis = 1))\n",
    "y_test = np.array(test.iloc[:,-5].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bb0e8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(train.drop('5세',axis = 1))\n",
    "y_train = np.array(train.iloc[:,-3].copy())\n",
    "X_test = np.array(test.drop('5세',axis = 1))\n",
    "y_test = np.array(test.iloc[:,-3].copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b3a4581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow --> 딥러닝 모델 기초설계\n",
    "# tensorflow.keras --> tensorflow를 사용하기쉽게 해주는 라이브러리\n",
    "import tensorflow.keras as tf\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9f38a1",
   "metadata": {},
   "source": [
    "## 부모키 추가했을 때 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "239b5f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 부모키 추가시\n",
    "sequential_model = tf.Sequential() # tf.Sequential() --> 기본틀 \n",
    "\n",
    "sequential_model.add(Dense(10,  activation='relu', input_shape = [22]))\n",
    "    \n",
    "# hidden layer\n",
    "sequential_model.add(Dense(64, activation='relu')) #Dense 하나하나가 hidden layer\n",
    "\n",
    "sequential_model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "sequential_model.add(Dense(1, activation='relu')) # activation function 에대해 조사할것"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292e8d8b",
   "metadata": {},
   "source": [
    "## 아이키만 사용했을 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99a54f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sequential_model = tf.Sequential() # tf.Sequential() --> 기본틀 \n",
    "\n",
    "sequential_model.add(Dense(10,  activation='relu', input_shape = [20]))\n",
    "    \n",
    "# hidden layer\n",
    "sequential_model.add(Dense(64, activation='relu')) #Dense 하나하나가 hidden layer\n",
    "\n",
    "sequential_model.add(Dense(64, activation='relu'))\n",
    "\n",
    "# output layer\n",
    "sequential_model.add(Dense(1, activation='relu')) # activation function 에대해 조사할것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83adb087",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequential_model.compile( optimizer='rmsprop',\n",
    "                         loss = 'mse'\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48cc1b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "4000/4000 [==============================] - 0s 51us/sample - loss: 264.0703 - val_loss: 23.1506\n",
      "Epoch 2/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 17.6459 - val_loss: 10.5298\n",
      "Epoch 3/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 14.4316 - val_loss: 16.7135\n",
      "Epoch 4/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 12.9868 - val_loss: 11.2302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2057: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 11.3782 - val_loss: 6.2471\n",
      "Epoch 6/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 9.9128 - val_loss: 9.9372\n",
      "Epoch 7/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 9.2814 - val_loss: 20.2787\n",
      "Epoch 8/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 8.7163 - val_loss: 11.7906\n",
      "Epoch 9/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 7.9548 - val_loss: 9.6468\n",
      "Epoch 10/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 7.5683 - val_loss: 6.8974\n",
      "Epoch 11/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 7.1864 - val_loss: 6.9934\n",
      "Epoch 12/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 6.8160 - val_loss: 5.2590\n",
      "Epoch 13/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 6.7393 - val_loss: 7.0073\n",
      "Epoch 14/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 6.6006 - val_loss: 2.0158\n",
      "Epoch 15/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 6.1302 - val_loss: 6.9920\n",
      "Epoch 16/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 5.9369 - val_loss: 10.1149\n",
      "Epoch 17/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 5.7939 - val_loss: 8.6635\n",
      "Epoch 18/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 5.7318 - val_loss: 5.5489\n",
      "Epoch 19/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 5.2102 - val_loss: 7.2468\n",
      "Epoch 20/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 5.1044 - val_loss: 5.2005\n",
      "Epoch 21/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 4.9897 - val_loss: 10.7396\n",
      "Epoch 22/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 5.0825 - val_loss: 4.4696\n",
      "Epoch 23/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 4.7287 - val_loss: 2.3677\n",
      "Epoch 24/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 4.8079 - val_loss: 4.4884\n",
      "Epoch 25/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 4.5479 - val_loss: 8.8897\n",
      "Epoch 26/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 4.5171 - val_loss: 6.5494\n",
      "Epoch 27/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 4.4678 - val_loss: 6.2977\n",
      "Epoch 28/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 4.3965 - val_loss: 0.6173\n",
      "Epoch 29/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 4.4668 - val_loss: 4.1118\n",
      "Epoch 30/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 4.3761 - val_loss: 4.1202\n",
      "Epoch 31/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 4.3787 - val_loss: 5.7147\n",
      "Epoch 32/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 4.1577 - val_loss: 1.8631\n",
      "Epoch 33/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 4.0588 - val_loss: 5.8001\n",
      "Epoch 34/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 3.9923 - val_loss: 1.5370\n",
      "Epoch 35/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.9022 - val_loss: 10.2950\n",
      "Epoch 36/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.8497 - val_loss: 1.6123\n",
      "Epoch 37/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.7955 - val_loss: 3.0949\n",
      "Epoch 38/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.9033 - val_loss: 1.3511\n",
      "Epoch 39/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.7137 - val_loss: 4.1863\n",
      "Epoch 40/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.6867 - val_loss: 3.0209\n",
      "Epoch 41/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.5353 - val_loss: 2.0666\n",
      "Epoch 42/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 3.6806 - val_loss: 5.6836\n",
      "Epoch 43/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.6019 - val_loss: 4.2316\n",
      "Epoch 44/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 3.5612 - val_loss: 4.4954\n",
      "Epoch 45/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.6197 - val_loss: 4.0039\n",
      "Epoch 46/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 3.5063 - val_loss: 2.1289\n",
      "Epoch 47/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.4591 - val_loss: 6.3409\n",
      "Epoch 48/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.5180 - val_loss: 2.3738\n",
      "Epoch 49/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.4682 - val_loss: 2.1563\n",
      "Epoch 50/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.3591 - val_loss: 2.0944\n",
      "Epoch 51/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.4292 - val_loss: 2.7852\n",
      "Epoch 52/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.4233 - val_loss: 3.0276\n",
      "Epoch 53/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.3987 - val_loss: 2.7425\n",
      "Epoch 54/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.3677 - val_loss: 2.0326\n",
      "Epoch 55/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.4021 - val_loss: 3.3244\n",
      "Epoch 56/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.3508 - val_loss: 3.5610\n",
      "Epoch 57/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.3140 - val_loss: 4.7965\n",
      "Epoch 58/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.3657 - val_loss: 2.1704\n",
      "Epoch 59/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.3057 - val_loss: 2.6499\n",
      "Epoch 60/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.3092 - val_loss: 6.5292\n",
      "Epoch 61/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.2603 - val_loss: 6.0493\n",
      "Epoch 62/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.3532 - val_loss: 3.6692\n",
      "Epoch 63/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 3.1817 - val_loss: 1.5994\n",
      "Epoch 64/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.2853 - val_loss: 2.9402\n",
      "Epoch 65/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.1476 - val_loss: 2.9105\n",
      "Epoch 66/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.1627 - val_loss: 3.2909\n",
      "Epoch 67/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 3.2174 - val_loss: 3.2111\n",
      "Epoch 68/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 3.1613 - val_loss: 3.0560\n",
      "Epoch 69/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 3.2029 - val_loss: 4.4177\n",
      "Epoch 70/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.1184 - val_loss: 1.9931\n",
      "Epoch 71/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 3.1452 - val_loss: 1.6834\n",
      "Epoch 72/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.1102 - val_loss: 3.3348\n",
      "Epoch 73/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.1921 - val_loss: 2.9640\n",
      "Epoch 74/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.1252 - val_loss: 2.2032\n",
      "Epoch 75/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.1365 - val_loss: 2.4034\n",
      "Epoch 76/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 3.0437 - val_loss: 3.2926\n",
      "Epoch 77/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 3.1131 - val_loss: 2.1356\n",
      "Epoch 78/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.0017 - val_loss: 5.9770\n",
      "Epoch 79/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.1188 - val_loss: 2.0876\n",
      "Epoch 80/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 3.0352 - val_loss: 1.9760\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.0934 - val_loss: 2.1489\n",
      "Epoch 82/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.0116 - val_loss: 1.3907\n",
      "Epoch 83/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 3.0554 - val_loss: 3.2098\n",
      "Epoch 84/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.0378 - val_loss: 3.5528\n",
      "Epoch 85/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.0578 - val_loss: 2.3615\n",
      "Epoch 86/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.0395 - val_loss: 2.6030\n",
      "Epoch 87/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 2.9909 - val_loss: 4.1033\n",
      "Epoch 88/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.0104 - val_loss: 2.9025\n",
      "Epoch 89/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.0047 - val_loss: 2.4391\n",
      "Epoch 90/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 2.8804 - val_loss: 4.1757\n",
      "Epoch 91/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 2.9788 - val_loss: 5.2240\n",
      "Epoch 92/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 2.9545 - val_loss: 3.8318\n",
      "Epoch 93/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 2.9676 - val_loss: 1.7260\n",
      "Epoch 94/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 2.9205 - val_loss: 2.3614\n",
      "Epoch 95/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 2.8558 - val_loss: 1.9178\n",
      "Epoch 96/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 2.9501 - val_loss: 3.3058\n",
      "Epoch 97/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 2.8732 - val_loss: 2.7436\n",
      "Epoch 98/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 2.9623 - val_loss: 1.5347\n",
      "Epoch 99/100\n",
      "4000/4000 [==============================] - 0s 14us/sample - loss: 3.0307 - val_loss: 0.6229\n",
      "Epoch 100/100\n",
      "4000/4000 [==============================] - 0s 13us/sample - loss: 2.9046 - val_loss: 2.0435\n"
     ]
    }
   ],
   "source": [
    "sequential_model.fit(X_train,\n",
    "                     y_train,\n",
    "                     batch_size=None, # 몇 개로 나누어 동시에 진행할 것인가\n",
    "                     epochs=100, # 훈련 몇번 진행할 것인지\n",
    "                     validation_split=0.2); # train데이터에서 일정 비율만큼 쪽지시험으로 놔둔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b8ae040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 50.96,  60.52,  63.12,  65.68,  67.07,  69.55,  70.86,  72.61,\n",
       "         73.55,  74.91,  76.49,  78.71,  81.54,  83.71,  86.2 ,  93.88,\n",
       "        103.07, 107.42,   1.  ,   0.  ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0].reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6736bba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\smhrd\\anaconda3\\lib\\site-packages\\keras\\engine\\training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[111.45145]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 \n",
    "sequential_model.predict(X_test[0].reshape(1, -1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f439fee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d376a7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[[ 50.96,  51.52,  52.12,  53.68,  0,  55.55,  56.86,  57.61,\n",
    "         58.55,  59.91,  60.49,  61.71,  62.54,  63.71,  67.2 ,  73.88,\n",
    "        82.07, 92.42,   1.  ,   0.  ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c5e2c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f6b3e9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8acda9e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50.96, 51.52, 52.12, 53.68,  0.  , 55.55, 56.86, 57.61, 58.55,\n",
       "        59.91, 60.49, 61.71, 62.54, 63.71, 67.2 , 73.88, 82.07, 92.42,\n",
       "         1.  ,  0.  ]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "75be96fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[75.668365]], dtype=float32)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequential_model.predict(x.reshape(1, -1 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eabcddf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5cd5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076edac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41d1926",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c39d23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f86fd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e96b058",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26722aa9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02f32c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a741a3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee2a8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdc1eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e794e01c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13ed8c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fdded8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bcb5f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6f639c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb26c54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "743px",
    "left": "58px",
    "top": "86px",
    "width": "197.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
