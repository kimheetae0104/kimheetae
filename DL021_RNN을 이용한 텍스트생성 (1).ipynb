{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 652,
     "status": "ok",
     "timestamp": 1618534396346,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "ozVhFv8gJPYM"
   },
   "outputs": [],
   "source": [
    "text=\"\"\"경마장에 있는 말이 뛰고 있다\\n\n",
    "그의 말이 법이다\\n\n",
    "가는 말이 고와야 오는 말이 곱다\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vy3JPwjZAv8T"
   },
   "source": [
    "### 단어 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 646,
     "status": "ok",
     "timestamp": 1618534397193,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "4pEYDLenfzOm",
    "outputId": "6168b253-396a-4b00-a54f-f922b32b2596"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'뛰고': 1,\n",
       "             '고와야': 1,\n",
       "             '곱다': 1,\n",
       "             '경마장에': 1,\n",
       "             '있다': 1,\n",
       "             '법이다': 1,\n",
       "             '가는': 1,\n",
       "             '있는': 1,\n",
       "             '오는': 1,\n",
       "             '그의': 1,\n",
       "             '말이': 1})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# 단어 분리\n",
    "t = Tokenizer()\n",
    "t.fit_on_texts([text])\n",
    "\n",
    "t.word_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 537,
     "status": "ok",
     "timestamp": 1618535847810,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "T6PS4X6Mf3Ar",
    "outputId": "496dcf42-1a97-4676-bfcc-c5316c99c015"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 12\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(t.word_index) + 1\n",
    "\n",
    "print('단어 집합의 크기 : %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 771,
     "status": "ok",
     "timestamp": 1618534398449,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "V4gtyUngf4qE",
    "outputId": "fb0b67e2-0f24-4b91-eaff-29607ec27949"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'말이': 1, '경마장에': 2, '있는': 3, '뛰고': 4, '있다': 5, '그의': 6, '법이다': 7, '가는': 8, '고와야': 9, '오는': 10, '곱다': 11}\n"
     ]
    }
   ],
   "source": [
    "# 단어와 인덱스 출력\n",
    "print(t.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHk_KjQ4A6Fu"
   },
   "source": [
    "### 토큰화와 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 583,
     "status": "ok",
     "timestamp": 1618535859294,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "_Nsd9anTf4_g",
    "outputId": "6b82ced5-6e42-49e5-add0-183a2c0dfb5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습에 사용할 샘플의 개수: 11\n"
     ]
    }
   ],
   "source": [
    "# 훈련 데이터 생성\n",
    "sequences = []\n",
    "\n",
    "# Wn을 기준으로 문장 토큰화\n",
    "for line in text.split('\\n'): \n",
    "  \n",
    "    # 단어를 정수로 변경\n",
    "    encoded = t.texts_to_sequences([line])[0]\n",
    "    \n",
    "    # 2개 이상의 모든 단의 조합을 생성\n",
    "    for i in range(1, len(encoded)):\n",
    "        sequence = encoded[:i+1]\n",
    "        sequences.append(sequence)\n",
    "\n",
    "print('학습에 사용할 샘플의 개수: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 745,
     "status": "ok",
     "timestamp": 1618534401463,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "3W5ag38Hf6gs",
    "outputId": "08c0bab4-55c4-4d03-f922-8fa6eb3195f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 3], [2, 3, 1], [2, 3, 1, 4], [2, 3, 1, 4, 5], [6, 1], [6, 1, 7], [8, 1], [8, 1, 9], [8, 1, 9, 10], [8, 1, 9, 10, 1], [8, 1, 9, 10, 1, 11]]\n"
     ]
    }
   ],
   "source": [
    "print(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PONkmw82rFYh"
   },
   "source": [
    "- 위의 데이터는 아직 레이블로 사용될 단어를 분리하지 않은 훈련 데이터\n",
    "\n",
    "- [2, 3] 은 [경마장에, 있는]에 해당되며 [2, 3, 1]은 [경마장에, 있는, 말이]에 해당\n",
    "\n",
    "- 전체 훈련 데이터에 대해서 맨 우측에 있는 단어에 대해서만 레이블로 분리해야 함\n",
    "\n",
    "- 우선 전체 샘플에 대해서 길이를 일치시켜 줍니다. 가장 긴 샘플의 길이를 기준\n",
    "\n",
    "- 길이가 가장 긴 샘플은 [8, 1, 9, 10, 1, 11]이고 길이는 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 366,
     "status": "ok",
     "timestamp": 1618534402184,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "eNOLWdb1f73_",
    "outputId": "0fe0d0b0-9d07-40d4-a7f0-ab7c23942695"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(max(len(l) for l in sequences)) # 모든 샘플에서 길이가 가장 긴 샘플의 길이 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vZMat2GwBL_E"
   },
   "source": [
    "### 입력할 내용을 일정한 길이로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 354,
     "status": "ok",
     "timestamp": 1618534403083,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "bi9RXP3Of9V9"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_len = 6\n",
    "\n",
    "# pad_sequences() : 모든 샘플에 대해서 0을 사용하여 길이를 맞춤 \n",
    "# pre : 길이가 6보다 짧은 샘플의 앞에 0으로 채움\n",
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 705,
     "status": "ok",
     "timestamp": 1618534403883,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "-UAMikNRf_dt",
    "outputId": "b277bcae-db13-4800-e387-d6c3a1b3cdc3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  2  3]\n",
      " [ 0  0  0  2  3  1]\n",
      " [ 0  0  2  3  1  4]\n",
      " [ 0  2  3  1  4  5]\n",
      " [ 0  0  0  0  6  1]\n",
      " [ 0  0  0  6  1  7]\n",
      " [ 0  0  0  0  8  1]\n",
      " [ 0  0  0  8  1  9]\n",
      " [ 0  0  8  1  9 10]\n",
      " [ 0  8  1  9 10  1]\n",
      " [ 8  1  9 10  1 11]]\n"
     ]
    }
   ],
   "source": [
    "print(sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5BvDY8aB7M5"
   },
   "source": [
    "### 특성과 라벨을 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 546,
     "status": "ok",
     "timestamp": 1618534405945,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "URADZp9dgAqd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 마지막 단어를 레이블로 분리\n",
    "sequences = np.array(sequences)\n",
    "\n",
    "X = sequences[:,:-1]\n",
    "y = sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 521,
     "status": "ok",
     "timestamp": 1618534406517,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "PoNjYf2AgCGn",
    "outputId": "53e7e917-f0e5-474a-8a92-586cc90625f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  0  0  2]\n",
      " [ 0  0  0  2  3]\n",
      " [ 0  0  2  3  1]\n",
      " [ 0  2  3  1  4]\n",
      " [ 0  0  0  0  6]\n",
      " [ 0  0  0  6  1]\n",
      " [ 0  0  0  0  8]\n",
      " [ 0  0  0  8  1]\n",
      " [ 0  0  8  1  9]\n",
      " [ 0  8  1  9 10]\n",
      " [ 8  1  9 10  1]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 558,
     "status": "ok",
     "timestamp": 1618534495186,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "s3zhq5OrgDF1",
    "outputId": "45e2513f-d720-4d6f-c534-51ee5eb8067f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  1  4  5  1  7  1  9 10  1 11]\n"
     ]
    }
   ],
   "source": [
    "print(y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LxinMk5-CFl6"
   },
   "source": [
    "### 원 핫 인코딩 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 572,
     "status": "ok",
     "timestamp": 1618536176637,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "TVIlLR-IgE8l"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# 첫 번째 인덱스는 사용하지 않음\n",
    "y_en = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 438,
     "status": "ok",
     "timestamp": 1618536178701,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "nG-G_q7JgHQk",
    "outputId": "dd3672d5-b023-4e6a-fc8d-a4627132824d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "print(y_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  2],\n",
       "       [ 0,  0,  0,  2,  3],\n",
       "       [ 0,  0,  2,  3,  1],\n",
       "       [ 0,  2,  3,  1,  4],\n",
       "       [ 0,  0,  0,  0,  6],\n",
       "       [ 0,  0,  0,  6,  1],\n",
       "       [ 0,  0,  0,  0,  8],\n",
       "       [ 0,  0,  0,  8,  1],\n",
       "       [ 0,  0,  8,  1,  9],\n",
       "       [ 0,  8,  1,  9, 10],\n",
       "       [ 8,  1,  9, 10,  1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 758\n"
     ]
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K3Q5gNlFCPDO"
   },
   "source": [
    "### 신경망 설계 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  2],\n",
       "       [ 0,  0,  0,  2,  3],\n",
       "       [ 0,  0,  2,  3,  1],\n",
       "       [ 0,  2,  3,  1,  4],\n",
       "       [ 0,  0,  0,  0,  6],\n",
       "       [ 0,  0,  0,  6,  1],\n",
       "       [ 0,  0,  0,  0,  8],\n",
       "       [ 0,  0,  0,  8,  1],\n",
       "       [ 0,  0,  8,  1,  9],\n",
       "       [ 0,  8,  1,  9, 10],\n",
       "       [ 8,  1,  9, 10,  1]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vocab_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12592/2711185169.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvocab_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'vocab_size' is not defined"
     ]
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 560,
     "status": "ok",
     "timestamp": 1618536185736,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "r8C5dZtCgJUU"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding, Dense, SimpleRNN\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "# 레이블을 분리하였으므로 이제 X의 길이는 5\n",
    "model.add(Embedding(vocab_size, 10, input_length=max_len-1)) \n",
    "model.add(SimpleRNN(32)) #분석\n",
    "model.add(Dense(vocab_size, activation='softmax')) #판단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4142,
     "status": "ok",
     "timestamp": 1618536191292,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "nC2Jy5VkgMNO",
    "outputId": "3f160621-4377-4413-c103-153c4036188f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11 samples\n",
      "Epoch 1/200\n",
      "11/11 - 1s - loss: 2.4687 - accuracy: 0.0909\n",
      "Epoch 2/200\n",
      "11/11 - 0s - loss: 2.4556 - accuracy: 0.1818\n",
      "Epoch 3/200\n",
      "11/11 - 0s - loss: 2.4425 - accuracy: 0.3636\n",
      "Epoch 4/200\n",
      "11/11 - 0s - loss: 2.4292 - accuracy: 0.3636\n",
      "Epoch 5/200\n",
      "11/11 - 0s - loss: 2.4155 - accuracy: 0.3636\n",
      "Epoch 6/200\n",
      "11/11 - 0s - loss: 2.4015 - accuracy: 0.3636\n",
      "Epoch 7/200\n",
      "11/11 - 0s - loss: 2.3870 - accuracy: 0.3636\n",
      "Epoch 8/200\n",
      "11/11 - 0s - loss: 2.3719 - accuracy: 0.3636\n",
      "Epoch 9/200\n",
      "11/11 - 0s - loss: 2.3562 - accuracy: 0.4545\n",
      "Epoch 10/200\n",
      "11/11 - 0s - loss: 2.3398 - accuracy: 0.4545\n",
      "Epoch 11/200\n",
      "11/11 - 0s - loss: 2.3228 - accuracy: 0.4545\n",
      "Epoch 12/200\n",
      "11/11 - 0s - loss: 2.3049 - accuracy: 0.4545\n",
      "Epoch 13/200\n",
      "11/11 - 0s - loss: 2.2864 - accuracy: 0.5455\n",
      "Epoch 14/200\n",
      "11/11 - 0s - loss: 2.2669 - accuracy: 0.5455\n",
      "Epoch 15/200\n",
      "11/11 - 0s - loss: 2.2467 - accuracy: 0.5455\n",
      "Epoch 16/200\n",
      "11/11 - 0s - loss: 2.2256 - accuracy: 0.4545\n",
      "Epoch 17/200\n",
      "11/11 - 0s - loss: 2.2036 - accuracy: 0.4545\n",
      "Epoch 18/200\n",
      "11/11 - 0s - loss: 2.1808 - accuracy: 0.4545\n",
      "Epoch 19/200\n",
      "11/11 - 0s - loss: 2.1571 - accuracy: 0.4545\n",
      "Epoch 20/200\n",
      "11/11 - 0s - loss: 2.1327 - accuracy: 0.4545\n",
      "Epoch 21/200\n",
      "11/11 - 0s - loss: 2.1075 - accuracy: 0.4545\n",
      "Epoch 22/200\n",
      "11/11 - 0s - loss: 2.0816 - accuracy: 0.4545\n",
      "Epoch 23/200\n",
      "11/11 - 0s - loss: 2.0552 - accuracy: 0.4545\n",
      "Epoch 24/200\n",
      "11/11 - 0s - loss: 2.0283 - accuracy: 0.4545\n",
      "Epoch 25/200\n",
      "11/11 - 0s - loss: 2.0011 - accuracy: 0.4545\n",
      "Epoch 26/200\n",
      "11/11 - 0s - loss: 1.9737 - accuracy: 0.4545\n",
      "Epoch 27/200\n",
      "11/11 - 0s - loss: 1.9464 - accuracy: 0.4545\n",
      "Epoch 28/200\n",
      "11/11 - 0s - loss: 1.9194 - accuracy: 0.4545\n",
      "Epoch 29/200\n",
      "11/11 - 0s - loss: 1.8927 - accuracy: 0.4545\n",
      "Epoch 30/200\n",
      "11/11 - 0s - loss: 1.8667 - accuracy: 0.3636\n",
      "Epoch 31/200\n",
      "11/11 - 0s - loss: 1.8414 - accuracy: 0.3636\n",
      "Epoch 32/200\n",
      "11/11 - 0s - loss: 1.8170 - accuracy: 0.3636\n",
      "Epoch 33/200\n",
      "11/11 - 0s - loss: 1.7935 - accuracy: 0.3636\n",
      "Epoch 34/200\n",
      "11/11 - 0s - loss: 1.7711 - accuracy: 0.3636\n",
      "Epoch 35/200\n",
      "11/11 - 0s - loss: 1.7496 - accuracy: 0.3636\n",
      "Epoch 36/200\n",
      "11/11 - 0s - loss: 1.7289 - accuracy: 0.3636\n",
      "Epoch 37/200\n",
      "11/11 - 0s - loss: 1.7089 - accuracy: 0.3636\n",
      "Epoch 38/200\n",
      "11/11 - 0s - loss: 1.6894 - accuracy: 0.4545\n",
      "Epoch 39/200\n",
      "11/11 - 0s - loss: 1.6701 - accuracy: 0.4545\n",
      "Epoch 40/200\n",
      "11/11 - 0s - loss: 1.6509 - accuracy: 0.4545\n",
      "Epoch 41/200\n",
      "11/11 - 0s - loss: 1.6316 - accuracy: 0.4545\n",
      "Epoch 42/200\n",
      "11/11 - 0s - loss: 1.6120 - accuracy: 0.4545\n",
      "Epoch 43/200\n",
      "11/11 - 0s - loss: 1.5920 - accuracy: 0.4545\n",
      "Epoch 44/200\n",
      "11/11 - 0s - loss: 1.5718 - accuracy: 0.4545\n",
      "Epoch 45/200\n",
      "11/11 - 0s - loss: 1.5512 - accuracy: 0.4545\n",
      "Epoch 46/200\n",
      "11/11 - 0s - loss: 1.5304 - accuracy: 0.4545\n",
      "Epoch 47/200\n",
      "11/11 - 0s - loss: 1.5094 - accuracy: 0.4545\n",
      "Epoch 48/200\n",
      "11/11 - 0s - loss: 1.4884 - accuracy: 0.4545\n",
      "Epoch 49/200\n",
      "11/11 - 0s - loss: 1.4673 - accuracy: 0.4545\n",
      "Epoch 50/200\n",
      "11/11 - 0s - loss: 1.4462 - accuracy: 0.4545\n",
      "Epoch 51/200\n",
      "11/11 - 0s - loss: 1.4252 - accuracy: 0.4545\n",
      "Epoch 52/200\n",
      "11/11 - 0s - loss: 1.4043 - accuracy: 0.4545\n",
      "Epoch 53/200\n",
      "11/11 - 0s - loss: 1.3834 - accuracy: 0.4545\n",
      "Epoch 54/200\n",
      "11/11 - 0s - loss: 1.3627 - accuracy: 0.4545\n",
      "Epoch 55/200\n",
      "11/11 - 0s - loss: 1.3420 - accuracy: 0.5455\n",
      "Epoch 56/200\n",
      "11/11 - 0s - loss: 1.3215 - accuracy: 0.5455\n",
      "Epoch 57/200\n",
      "11/11 - 0s - loss: 1.3012 - accuracy: 0.5455\n",
      "Epoch 58/200\n",
      "11/11 - 0s - loss: 1.2811 - accuracy: 0.6364\n",
      "Epoch 59/200\n",
      "11/11 - 0s - loss: 1.2612 - accuracy: 0.6364\n",
      "Epoch 60/200\n",
      "11/11 - 0s - loss: 1.2415 - accuracy: 0.6364\n",
      "Epoch 61/200\n",
      "11/11 - 0s - loss: 1.2222 - accuracy: 0.7273\n",
      "Epoch 62/200\n",
      "11/11 - 0s - loss: 1.2032 - accuracy: 0.7273\n",
      "Epoch 63/200\n",
      "11/11 - 0s - loss: 1.1845 - accuracy: 0.7273\n",
      "Epoch 64/200\n",
      "11/11 - 0s - loss: 1.1661 - accuracy: 0.7273\n",
      "Epoch 65/200\n",
      "11/11 - 0s - loss: 1.1481 - accuracy: 0.7273\n",
      "Epoch 66/200\n",
      "11/11 - 0s - loss: 1.1303 - accuracy: 0.7273\n",
      "Epoch 67/200\n",
      "11/11 - 0s - loss: 1.1128 - accuracy: 0.7273\n",
      "Epoch 68/200\n",
      "11/11 - 0s - loss: 1.0956 - accuracy: 0.7273\n",
      "Epoch 69/200\n",
      "11/11 - 0s - loss: 1.0786 - accuracy: 0.7273\n",
      "Epoch 70/200\n",
      "11/11 - 0s - loss: 1.0619 - accuracy: 0.7273\n",
      "Epoch 71/200\n",
      "11/11 - 0s - loss: 1.0454 - accuracy: 0.7273\n",
      "Epoch 72/200\n",
      "11/11 - 0s - loss: 1.0291 - accuracy: 0.7273\n",
      "Epoch 73/200\n",
      "11/11 - 0s - loss: 1.0130 - accuracy: 0.7273\n",
      "Epoch 74/200\n",
      "11/11 - 0s - loss: 0.9971 - accuracy: 0.7273\n",
      "Epoch 75/200\n",
      "11/11 - 0s - loss: 0.9815 - accuracy: 0.7273\n",
      "Epoch 76/200\n",
      "11/11 - 0s - loss: 0.9661 - accuracy: 0.7273\n",
      "Epoch 77/200\n",
      "11/11 - 0s - loss: 0.9509 - accuracy: 0.7273\n",
      "Epoch 78/200\n",
      "11/11 - 0s - loss: 0.9359 - accuracy: 0.7273\n",
      "Epoch 79/200\n",
      "11/11 - 0s - loss: 0.9211 - accuracy: 0.8182\n",
      "Epoch 80/200\n",
      "11/11 - 0s - loss: 0.9066 - accuracy: 0.8182\n",
      "Epoch 81/200\n",
      "11/11 - 0s - loss: 0.8922 - accuracy: 0.8182\n",
      "Epoch 82/200\n",
      "11/11 - 0s - loss: 0.8780 - accuracy: 0.8182\n",
      "Epoch 83/200\n",
      "11/11 - 0s - loss: 0.8641 - accuracy: 0.8182\n",
      "Epoch 84/200\n",
      "11/11 - 0s - loss: 0.8503 - accuracy: 0.8182\n",
      "Epoch 85/200\n",
      "11/11 - 0s - loss: 0.8367 - accuracy: 0.8182\n",
      "Epoch 86/200\n",
      "11/11 - 0s - loss: 0.8233 - accuracy: 0.8182\n",
      "Epoch 87/200\n",
      "11/11 - 0s - loss: 0.8100 - accuracy: 0.8182\n",
      "Epoch 88/200\n",
      "11/11 - 0s - loss: 0.7970 - accuracy: 0.8182\n",
      "Epoch 89/200\n",
      "11/11 - 0s - loss: 0.7842 - accuracy: 0.8182\n",
      "Epoch 90/200\n",
      "11/11 - 0s - loss: 0.7715 - accuracy: 0.8182\n",
      "Epoch 91/200\n",
      "11/11 - 0s - loss: 0.7590 - accuracy: 0.8182\n",
      "Epoch 92/200\n",
      "11/11 - 0s - loss: 0.7467 - accuracy: 0.8182\n",
      "Epoch 93/200\n",
      "11/11 - 0s - loss: 0.7345 - accuracy: 0.8182\n",
      "Epoch 94/200\n",
      "11/11 - 0s - loss: 0.7225 - accuracy: 0.8182\n",
      "Epoch 95/200\n",
      "11/11 - 0s - loss: 0.7107 - accuracy: 0.8182\n",
      "Epoch 96/200\n",
      "11/11 - 0s - loss: 0.6990 - accuracy: 0.8182\n",
      "Epoch 97/200\n",
      "11/11 - 0s - loss: 0.6876 - accuracy: 0.8182\n",
      "Epoch 98/200\n",
      "11/11 - 0s - loss: 0.6763 - accuracy: 0.9091\n",
      "Epoch 99/200\n",
      "11/11 - 0s - loss: 0.6651 - accuracy: 0.9091\n",
      "Epoch 100/200\n",
      "11/11 - 0s - loss: 0.6541 - accuracy: 0.9091\n",
      "Epoch 101/200\n",
      "11/11 - 0s - loss: 0.6433 - accuracy: 0.9091\n",
      "Epoch 102/200\n",
      "11/11 - 0s - loss: 0.6327 - accuracy: 0.9091\n",
      "Epoch 103/200\n",
      "11/11 - 0s - loss: 0.6222 - accuracy: 0.9091\n",
      "Epoch 104/200\n",
      "11/11 - 0s - loss: 0.6118 - accuracy: 0.9091\n",
      "Epoch 105/200\n",
      "11/11 - 0s - loss: 0.6017 - accuracy: 0.9091\n",
      "Epoch 106/200\n",
      "11/11 - 0s - loss: 0.5917 - accuracy: 0.9091\n",
      "Epoch 107/200\n",
      "11/11 - 0s - loss: 0.5818 - accuracy: 0.9091\n",
      "Epoch 108/200\n",
      "11/11 - 0s - loss: 0.5721 - accuracy: 0.9091\n",
      "Epoch 109/200\n",
      "11/11 - 0s - loss: 0.5626 - accuracy: 0.9091\n",
      "Epoch 110/200\n",
      "11/11 - 0s - loss: 0.5532 - accuracy: 0.9091\n",
      "Epoch 111/200\n",
      "11/11 - 0s - loss: 0.5439 - accuracy: 0.9091\n",
      "Epoch 112/200\n",
      "11/11 - 0s - loss: 0.5349 - accuracy: 0.9091\n",
      "Epoch 113/200\n",
      "11/11 - 0s - loss: 0.5259 - accuracy: 0.9091\n",
      "Epoch 114/200\n",
      "11/11 - 0s - loss: 0.5172 - accuracy: 0.9091\n",
      "Epoch 115/200\n",
      "11/11 - 0s - loss: 0.5086 - accuracy: 0.9091\n",
      "Epoch 116/200\n",
      "11/11 - 0s - loss: 0.5001 - accuracy: 0.9091\n",
      "Epoch 117/200\n",
      "11/11 - 0s - loss: 0.4918 - accuracy: 0.9091\n",
      "Epoch 118/200\n",
      "11/11 - 0s - loss: 0.4836 - accuracy: 0.9091\n",
      "Epoch 119/200\n",
      "11/11 - 0s - loss: 0.4756 - accuracy: 0.9091\n",
      "Epoch 120/200\n",
      "11/11 - 0s - loss: 0.4677 - accuracy: 0.9091\n",
      "Epoch 121/200\n",
      "11/11 - 0s - loss: 0.4600 - accuracy: 0.9091\n",
      "Epoch 122/200\n",
      "11/11 - 0s - loss: 0.4524 - accuracy: 0.9091\n",
      "Epoch 123/200\n",
      "11/11 - 0s - loss: 0.4450 - accuracy: 0.9091\n",
      "Epoch 124/200\n",
      "11/11 - 0s - loss: 0.4377 - accuracy: 0.9091\n",
      "Epoch 125/200\n",
      "11/11 - 0s - loss: 0.4305 - accuracy: 0.9091\n",
      "Epoch 126/200\n",
      "11/11 - 0s - loss: 0.4235 - accuracy: 0.9091\n",
      "Epoch 127/200\n",
      "11/11 - 0s - loss: 0.4166 - accuracy: 0.9091\n",
      "Epoch 128/200\n",
      "11/11 - 0s - loss: 0.4099 - accuracy: 0.9091\n",
      "Epoch 129/200\n",
      "11/11 - 0s - loss: 0.4032 - accuracy: 0.9091\n",
      "Epoch 130/200\n",
      "11/11 - 0s - loss: 0.3967 - accuracy: 0.9091\n",
      "Epoch 131/200\n",
      "11/11 - 0s - loss: 0.3903 - accuracy: 0.9091\n",
      "Epoch 132/200\n",
      "11/11 - 0s - loss: 0.3840 - accuracy: 0.9091\n",
      "Epoch 133/200\n",
      "11/11 - 0s - loss: 0.3779 - accuracy: 0.9091\n",
      "Epoch 134/200\n",
      "11/11 - 0s - loss: 0.3718 - accuracy: 0.9091\n",
      "Epoch 135/200\n",
      "11/11 - 0s - loss: 0.3659 - accuracy: 0.9091\n",
      "Epoch 136/200\n",
      "11/11 - 0s - loss: 0.3601 - accuracy: 0.9091\n",
      "Epoch 137/200\n",
      "11/11 - 0s - loss: 0.3543 - accuracy: 0.9091\n",
      "Epoch 138/200\n",
      "11/11 - 0s - loss: 0.3487 - accuracy: 0.9091\n",
      "Epoch 139/200\n",
      "11/11 - 0s - loss: 0.3432 - accuracy: 0.9091\n",
      "Epoch 140/200\n",
      "11/11 - 0s - loss: 0.3377 - accuracy: 0.9091\n",
      "Epoch 141/200\n",
      "11/11 - 0s - loss: 0.3324 - accuracy: 0.9091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/200\n",
      "11/11 - 0s - loss: 0.3271 - accuracy: 0.9091\n",
      "Epoch 143/200\n",
      "11/11 - 0s - loss: 0.3219 - accuracy: 0.9091\n",
      "Epoch 144/200\n",
      "11/11 - 0s - loss: 0.3168 - accuracy: 0.9091\n",
      "Epoch 145/200\n",
      "11/11 - 0s - loss: 0.3118 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "11/11 - 0s - loss: 0.3068 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "11/11 - 0s - loss: 0.3019 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "11/11 - 0s - loss: 0.2971 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "11/11 - 0s - loss: 0.2924 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "11/11 - 0s - loss: 0.2877 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "11/11 - 0s - loss: 0.2831 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "11/11 - 0s - loss: 0.2785 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "11/11 - 0s - loss: 0.2740 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "11/11 - 0s - loss: 0.2696 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "11/11 - 0s - loss: 0.2652 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "11/11 - 0s - loss: 0.2609 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "11/11 - 0s - loss: 0.2566 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "11/11 - 0s - loss: 0.2524 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "11/11 - 0s - loss: 0.2482 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "11/11 - 0s - loss: 0.2441 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "11/11 - 0s - loss: 0.2401 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "11/11 - 0s - loss: 0.2361 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "11/11 - 0s - loss: 0.2321 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "11/11 - 0s - loss: 0.2282 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "11/11 - 0s - loss: 0.2243 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "11/11 - 0s - loss: 0.2205 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "11/11 - 0s - loss: 0.2168 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "11/11 - 0s - loss: 0.2131 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "11/11 - 0s - loss: 0.2094 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "11/11 - 0s - loss: 0.2058 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "11/11 - 0s - loss: 0.2022 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "11/11 - 0s - loss: 0.1987 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "11/11 - 0s - loss: 0.1953 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "11/11 - 0s - loss: 0.1918 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "11/11 - 0s - loss: 0.1885 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "11/11 - 0s - loss: 0.1852 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "11/11 - 0s - loss: 0.1819 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "11/11 - 0s - loss: 0.1787 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "11/11 - 0s - loss: 0.1755 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "11/11 - 0s - loss: 0.1724 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "11/11 - 0s - loss: 0.1693 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "11/11 - 0s - loss: 0.1663 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "11/11 - 0s - loss: 0.1633 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "11/11 - 0s - loss: 0.1604 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "11/11 - 0s - loss: 0.1575 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "11/11 - 0s - loss: 0.1547 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "11/11 - 0s - loss: 0.1519 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "11/11 - 0s - loss: 0.1492 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "11/11 - 0s - loss: 0.1465 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "11/11 - 0s - loss: 0.1438 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "11/11 - 0s - loss: 0.1413 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "11/11 - 0s - loss: 0.1387 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "11/11 - 0s - loss: 0.1362 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "11/11 - 0s - loss: 0.1338 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "11/11 - 0s - loss: 0.1314 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "11/11 - 0s - loss: 0.1290 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "11/11 - 0s - loss: 0.1267 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "11/11 - 0s - loss: 0.1244 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "11/11 - 0s - loss: 0.1222 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "11/11 - 0s - loss: 0.1200 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f80dfb1f28>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y_en, epochs=200, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5juU2s0Cip4"
   },
   "source": [
    "## 문장을 생성하는 sentence_generation() 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('말이', 1), ('경마장에', 2), ('있는', 3), ('뛰고', 4), ('있다', 5), ('그의', 6), ('법이다', 7), ('가는', 8), ('고와야', 9), ('오는', 10), ('곱다', 11)])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.word_index.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 846,
     "status": "ok",
     "timestamp": 1618536202027,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "OLdG3vvmgPbW"
   },
   "outputs": [],
   "source": [
    "# 사용할 모델, 토크나이저, 현재 단어, 생성할 단어 수\n",
    "def sentence_generation(model, t, current_word, n): \n",
    "    init_word = current_word # 처음 들어온 단어도 마지막에 같이 출력하기 위해 저장\n",
    "    sentence = ''\n",
    "    for _ in range(n): # n번 반복\n",
    "        # 현재 단어에 대한 정수 인코딩\n",
    "        encoded = t.texts_to_sequences([current_word])[0] \n",
    "        print(encoded)\n",
    "        # 데이터를 같은 길이로 맞춤 (pre : 앞 부분에 0을 추가, post : 뒷 부분에 0을 추가)\n",
    "        encoded = pad_sequences([encoded], maxlen=max_len-1, padding='pre') \n",
    "        # 입력한 X(현재 단어)에 대해서 y를 예측하고 y(예측한 단어)를 result에 저장.\n",
    "        result = model.predict_classes(encoded, verbose=0)        \n",
    "        \n",
    "        for word, index in t.word_index.items(): \n",
    "            # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
    "            # 해당 단어가 예측 단어이므로 break\n",
    "            if index == result: \n",
    "                break \n",
    "        # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경        \n",
    "        current_word = current_word + ' '  + word \n",
    "        # 예측 단어를 문장에 저장\n",
    "        sentence = sentence + ' ' + word \n",
    "\n",
    "    # 문장 생성\n",
    "    sentence = init_word + sentence\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_vplA20C6vt"
   },
   "source": [
    "### 임의의 단어로 시작하는 설정 개수만큼의 단어로 문장을 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 586,
     "status": "ok",
     "timestamp": 1618536204258,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "FyxuD_3CgRWs",
    "outputId": "0eb2973a-6988-48c1-bb83-d45d9f593a84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "[2, 3]\n",
      "[2, 3, 1]\n",
      "[2, 3, 1, 4]\n",
      "경마장에 있는 말이 뛰고 있다\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, t, '경마장에', 4))\n",
    "# '경마장에' 라는 단어 뒤에는 총 4개의 단어가 있으므로 4번 예측 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 546,
     "status": "ok",
     "timestamp": 1618535561053,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "Zqyht6EfgSwZ",
    "outputId": "b809f368-9337-448c-a18a-b187049555e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\n",
      "[6, 1]\n",
      "그의 말이 법이다\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, t, '그의', 2)) # 2번 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 665,
     "status": "ok",
     "timestamp": 1618535565494,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "IZKB_Nk7gTM9",
    "outputId": "8754665d-8793-4cab-ba5e-e6d8090ecc99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\n",
      "[8, 1]\n",
      "[8, 1, 9]\n",
      "[8, 1, 9, 10]\n",
      "[8, 1, 9, 10, 1]\n",
      "가는 말이 고와야 오는 말이 곱다\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, t, '가는', 5)) # 5번 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwC3ZBDrgVcV"
   },
   "source": [
    "## LSTM을 이용하여 텍스트 생성 (더 많은 데이터 활용)\n",
    "\n",
    "- 뉴욕 타임즈 기사 다운로드 : https://www.kaggle.com/aashita/nyt-comments\n",
    "\n",
    "- 빅카인즈 뉴스기사 데이터 활용(https://www.bigkinds.or.kr/)\n",
    "\n",
    "(1) 검색키워드 입력\n",
    "\n",
    "(2) 하단의 \"뉴스분석\" 버튼 클릭\n",
    "\n",
    "(3) 하단의 \"다운로드\" 버튼 클릭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21859,
     "status": "ok",
     "timestamp": 1618532895240,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "RukAjHmWKa0i",
    "outputId": "3b880b27-2334-456d-917c-61ead4f60b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /gdrive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5870,
     "status": "ok",
     "timestamp": 1618532906363,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "oZ6HhTLjWSqF",
    "outputId": "86ce7f95-5a3a-49e3-94c1-60a9983ce442"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting konlpy\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
      "\u001b[K     |████████████████████████████████| 19.4MB 1.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
      "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
      "Collecting beautifulsoup4==4.6.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 11.3MB/s \n",
      "\u001b[?25hCollecting colorama\n",
      "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
      "Collecting JPype1>=0.7.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/a5/9781e2ef4ca92d09912c4794642c1653aea7607f473e156cf4d423a881a1/JPype1-1.2.1-cp37-cp37m-manylinux2010_x86_64.whl (457kB)\n",
      "\u001b[K     |████████████████████████████████| 460kB 48.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
      "Installing collected packages: beautifulsoup4, colorama, JPype1, konlpy\n",
      "  Found existing installation: beautifulsoup4 4.6.3\n",
      "    Uninstalling beautifulsoup4-4.6.3:\n",
      "      Successfully uninstalled beautifulsoup4-4.6.3\n",
      "Successfully installed JPype1-1.2.1 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 3212,
     "status": "ok",
     "timestamp": 1618532910909,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "YpfEFmkySLCH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "# \"미국 대선\"으로 검색한 데이터\n",
    "news = pd.read_excel(\"/gdrive/My Drive/Colab Notebooks/인공지능강의안/data/news_data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1889,
     "status": "ok",
     "timestamp": 1618532939423,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "xBUFPVDPVyq-",
    "outputId": "0572ac41-778d-463d-8624-e56a2bebe775"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['바이든', '대', '주주', '요건', '완화', '활짝', '웃다', '코스피', '앞', '쭉'],\n",
       " ['강경화', '대선', '후', '미국', '행', '이인영', '방미', '추진'],\n",
       " ['백악관', '주변', '대형', '울타리', '설치', '미국', '대선', '긴장', '고조'],\n",
       " ['역사상', '가장', '살벌하다', '선거', '워싱턴', '곳곳', '주', '방위', '군', '배치'],\n",
       " ['경합주', '박빙', '백인', '블루', '칼라', '사커맘', '표심', '변수']]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news['제목'] = news['제목'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣0-9 ]\",\"\") \n",
    "\n",
    "headline = []\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "stopwords=['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와', '등', '으로도']\n",
    "\n",
    "for sentence in news['제목']:\n",
    "    temp_X = []\n",
    "    temp_X=okt.morphs(sentence, stem=True) \n",
    "    temp_X=[word for word in temp_X if not word in stopwords] \n",
    "    headline.append(temp_X)\n",
    "\n",
    "headline[:5]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3667,
     "status": "ok",
     "timestamp": 1618532955617,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "UAgk-A_tXQVp",
    "outputId": "34958393-a08e-4f14-ef50-459fe86d3833"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 53, 178, 301, 302, 303, 179, 42, 180, 304],\n",
       " [87, 1, 305, 4, 181, 27, 54, 55],\n",
       " [115, 306, 307, 308, 182, 4, 1, 183, 309],\n",
       " [184, 116, 310, 23, 311, 117, 28, 70, 56, 118],\n",
       " [15, 119, 312, 313, 314, 315, 316, 317]]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "max_feature = 5000\n",
    "tokenizer = Tokenizer(num_words=max_feature) \n",
    "# 단어에 인덱스를 부여하기 위한 분석\n",
    "tokenizer.fit_on_texts(headline)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# 문자열을 정수 인덱스의 리스트로 변환\n",
    "headline_en = tokenizer.texts_to_sequences(headline)\n",
    "\n",
    "headline_en[:5]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1084,
     "status": "ok",
     "timestamp": 1618532986034,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "MyBGf20TYqux",
    "outputId": "d5649710-096e-4bd3-c98e-76e0423cd8a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 53],\n",
       " [3, 53, 178],\n",
       " [3, 53, 178, 301],\n",
       " [3, 53, 178, 301, 302],\n",
       " [3, 53, 178, 301, 302, 303],\n",
       " [3, 53, 178, 301, 302, 303, 179],\n",
       " [3, 53, 178, 301, 302, 303, 179, 42],\n",
       " [3, 53, 178, 301, 302, 303, 179, 42, 180],\n",
       " [3, 53, 178, 301, 302, 303, 179, 42, 180, 304],\n",
       " [87, 1],\n",
       " [87, 1, 305]]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = list()\n",
    "\n",
    "# 샘플을 1개씩 가져온다.\n",
    "for line in headline_en: \n",
    "    # 각 단어들로 구성된 모든 문장 조합을 생성\n",
    "    for i in range(1, len(line)):\n",
    "        sequence = line[:i+1]\n",
    "        sequences.append(sequence)\n",
    "\n",
    "# 11개의 샘플 출력\n",
    "sequences[:11] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 540,
     "status": "ok",
     "timestamp": 1618533082100,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "NL2xI6rpZAe9",
    "outputId": "3d41164e-7669-49a7-8c6e-1765a3013e70"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'믿다'"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_word={}\n",
    "\n",
    "# 인덱스를 단어로 바꾸기 위해 index_to_word를 생성\n",
    "for key, value in tokenizer.word_index.items(): \n",
    "    index_to_word[value] = key\n",
    "\n",
    "index_to_word[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WBb6dsAbGLkk"
   },
   "outputs": [],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 498,
     "status": "ok",
     "timestamp": 1618533272448,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "UVXnOSLDZL58",
    "outputId": "4b0daaa5-573c-4fe2-9f20-6e823116a0d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "# 문장의 최대 길이\n",
    "max_len=max(len(s) for s in sequences)\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "axV_qigvZUmD"
   },
   "source": [
    "### (실습) 입력할 내용을 일정한 길이로 변경\n",
    "\n",
    "- maxlen=max_len로 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1618533380898,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "eyM3JwD7ZUmE",
    "outputId": "d3fe1fef-d49c-489f-d3fc-39e3b1be9905"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3\n",
      "   53]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3  53\n",
      "  178]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3  53 178\n",
      "  301]]\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')\n",
    "\n",
    "print(sequences[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WLtNqsdZUmG"
   },
   "source": [
    "### (실습) 특성과 라벨을 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 564,
     "status": "ok",
     "timestamp": 1618533400549,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "36CcCZFZZUmG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "sequences = np.array(sequences)\n",
    "\n",
    "X = sequences[:,:-1]\n",
    "y = sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 564,
     "status": "ok",
     "timestamp": 1618533458942,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "tzAs28R_ZUmJ",
    "outputId": "0790e5b4-0e90-4c18-bda7-eb41d47b9a7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3  53]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3  53 178]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   3  53 178 301]]\n"
     ]
    }
   ],
   "source": [
    "print(X[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 561,
     "status": "ok",
     "timestamp": 1618533451275,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "dYpofLr9ZUmK",
    "outputId": "d00d4396-ec4b-41af-f1f0-9d1e9d28fcb5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 53 178 301]\n"
     ]
    }
   ],
   "source": [
    "print(y[:3]) # 레이블"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iiXLSwFYZUmM"
   },
   "source": [
    "### (실습) 원 핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 533,
     "status": "ok",
     "timestamp": 1618533470354,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "Qc3ltoY_ZUmM"
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GgADjoEZUmN"
   },
   "source": [
    "### (실습) 신경망 설계 (Embedding, LSTM/GRU) / complie / fit 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 106691,
     "status": "ok",
     "timestamp": 1618533594953,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "Z8tCUb1oZUmO",
    "outputId": "f2ac87e1-9d19-46ae-e9e7-1bc6e2f17e33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "61/61 [==============================] - 34s 10ms/step - loss: 6.5983 - accuracy: 0.0237\n",
      "Epoch 2/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 6.0702 - accuracy: 0.0377\n",
      "Epoch 3/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 6.0320 - accuracy: 0.0359\n",
      "Epoch 4/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 6.0002 - accuracy: 0.0410\n",
      "Epoch 5/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 5.9883 - accuracy: 0.0414\n",
      "Epoch 6/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 5.8843 - accuracy: 0.0431\n",
      "Epoch 7/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 5.8458 - accuracy: 0.0456\n",
      "Epoch 8/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 5.7690 - accuracy: 0.0442\n",
      "Epoch 9/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 5.6996 - accuracy: 0.0419\n",
      "Epoch 10/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 5.5351 - accuracy: 0.0507\n",
      "Epoch 11/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 5.4773 - accuracy: 0.0471\n",
      "Epoch 12/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 5.3229 - accuracy: 0.0680\n",
      "Epoch 13/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 5.2005 - accuracy: 0.0623\n",
      "Epoch 14/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 5.1609 - accuracy: 0.0677\n",
      "Epoch 15/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 5.0034 - accuracy: 0.0837\n",
      "Epoch 16/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 4.8247 - accuracy: 0.0793\n",
      "Epoch 17/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 4.7119 - accuracy: 0.0965\n",
      "Epoch 18/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 4.6598 - accuracy: 0.0851\n",
      "Epoch 19/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 4.4834 - accuracy: 0.1088\n",
      "Epoch 20/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 4.4117 - accuracy: 0.1067\n",
      "Epoch 21/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 4.2900 - accuracy: 0.1253\n",
      "Epoch 22/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 4.1197 - accuracy: 0.1553\n",
      "Epoch 23/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 3.9935 - accuracy: 0.1665\n",
      "Epoch 24/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 3.9239 - accuracy: 0.1740\n",
      "Epoch 25/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 3.8197 - accuracy: 0.1866\n",
      "Epoch 26/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 3.7583 - accuracy: 0.1984\n",
      "Epoch 27/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 3.6003 - accuracy: 0.2217\n",
      "Epoch 28/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 3.6119 - accuracy: 0.2382\n",
      "Epoch 29/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 3.4799 - accuracy: 0.2730\n",
      "Epoch 30/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 3.3765 - accuracy: 0.2934\n",
      "Epoch 31/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 3.2779 - accuracy: 0.3115\n",
      "Epoch 32/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 3.1475 - accuracy: 0.3434\n",
      "Epoch 33/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 3.0686 - accuracy: 0.3785\n",
      "Epoch 34/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 2.9837 - accuracy: 0.3791\n",
      "Epoch 35/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 2.9161 - accuracy: 0.3991\n",
      "Epoch 36/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 2.8929 - accuracy: 0.4147\n",
      "Epoch 37/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 2.7993 - accuracy: 0.4329\n",
      "Epoch 38/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 2.7205 - accuracy: 0.4500\n",
      "Epoch 39/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 2.6186 - accuracy: 0.4696\n",
      "Epoch 40/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 2.5256 - accuracy: 0.5056\n",
      "Epoch 41/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 2.5247 - accuracy: 0.4903\n",
      "Epoch 42/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 2.4392 - accuracy: 0.5205\n",
      "Epoch 43/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 2.3623 - accuracy: 0.5430\n",
      "Epoch 44/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 2.2745 - accuracy: 0.5485\n",
      "Epoch 45/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 2.2502 - accuracy: 0.5665\n",
      "Epoch 46/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 2.1865 - accuracy: 0.5739\n",
      "Epoch 47/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 2.1660 - accuracy: 0.5610\n",
      "Epoch 48/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 2.1314 - accuracy: 0.5752\n",
      "Epoch 49/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 2.0171 - accuracy: 0.6021\n",
      "Epoch 50/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 1.9633 - accuracy: 0.6157\n",
      "Epoch 51/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 1.9481 - accuracy: 0.6241\n",
      "Epoch 52/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 1.8945 - accuracy: 0.6372\n",
      "Epoch 53/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 1.8388 - accuracy: 0.6357\n",
      "Epoch 54/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 1.8116 - accuracy: 0.6485\n",
      "Epoch 55/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 1.7692 - accuracy: 0.6532\n",
      "Epoch 56/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 1.7085 - accuracy: 0.6604\n",
      "Epoch 57/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 1.6802 - accuracy: 0.6698\n",
      "Epoch 58/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 1.6944 - accuracy: 0.6675\n",
      "Epoch 59/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 1.6268 - accuracy: 0.6855\n",
      "Epoch 60/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 1.5581 - accuracy: 0.6854\n",
      "Epoch 61/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 1.5442 - accuracy: 0.7024\n",
      "Epoch 62/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 1.5326 - accuracy: 0.6945\n",
      "Epoch 63/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 1.5410 - accuracy: 0.6956\n",
      "Epoch 64/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 1.4646 - accuracy: 0.7150\n",
      "Epoch 65/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 1.4324 - accuracy: 0.7089\n",
      "Epoch 66/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 1.3825 - accuracy: 0.7299\n",
      "Epoch 67/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 1.3550 - accuracy: 0.7284\n",
      "Epoch 68/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 1.2652 - accuracy: 0.7507\n",
      "Epoch 69/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 1.2779 - accuracy: 0.7455\n",
      "Epoch 70/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 1.2231 - accuracy: 0.7636\n",
      "Epoch 71/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 1.2700 - accuracy: 0.7394\n",
      "Epoch 72/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 1.2665 - accuracy: 0.7428\n",
      "Epoch 73/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 1.2295 - accuracy: 0.7482\n",
      "Epoch 74/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 1.1784 - accuracy: 0.7670\n",
      "Epoch 75/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 1.1662 - accuracy: 0.7608\n",
      "Epoch 76/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 1.1261 - accuracy: 0.7790\n",
      "Epoch 77/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 1.0811 - accuracy: 0.7836\n",
      "Epoch 78/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 1.0913 - accuracy: 0.7783\n",
      "Epoch 79/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 1.0442 - accuracy: 0.7956\n",
      "Epoch 80/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 1.0439 - accuracy: 0.7829\n",
      "Epoch 81/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.9947 - accuracy: 0.8034\n",
      "Epoch 82/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.9911 - accuracy: 0.8062\n",
      "Epoch 83/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.9594 - accuracy: 0.8091\n",
      "Epoch 84/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.9779 - accuracy: 0.8109\n",
      "Epoch 85/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.9560 - accuracy: 0.8092\n",
      "Epoch 86/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.9283 - accuracy: 0.8158\n",
      "Epoch 87/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.9258 - accuracy: 0.8261\n",
      "Epoch 88/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.9079 - accuracy: 0.8170\n",
      "Epoch 89/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.8909 - accuracy: 0.8243\n",
      "Epoch 90/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.8343 - accuracy: 0.8405\n",
      "Epoch 91/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.7920 - accuracy: 0.8571\n",
      "Epoch 92/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.7991 - accuracy: 0.8413\n",
      "Epoch 93/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.7952 - accuracy: 0.8517\n",
      "Epoch 94/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.7962 - accuracy: 0.8403\n",
      "Epoch 95/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.7670 - accuracy: 0.8535\n",
      "Epoch 96/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.7666 - accuracy: 0.8446\n",
      "Epoch 97/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.7477 - accuracy: 0.8483\n",
      "Epoch 98/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.7293 - accuracy: 0.8590\n",
      "Epoch 99/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.7168 - accuracy: 0.8572\n",
      "Epoch 100/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.7500 - accuracy: 0.8499\n",
      "Epoch 101/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.7004 - accuracy: 0.8584\n",
      "Epoch 102/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.6710 - accuracy: 0.8643\n",
      "Epoch 103/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.6662 - accuracy: 0.8720\n",
      "Epoch 104/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.6476 - accuracy: 0.8686\n",
      "Epoch 105/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.7169 - accuracy: 0.8453\n",
      "Epoch 106/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.6576 - accuracy: 0.8714\n",
      "Epoch 107/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.6373 - accuracy: 0.8653\n",
      "Epoch 108/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.6140 - accuracy: 0.8772\n",
      "Epoch 109/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.6186 - accuracy: 0.8760\n",
      "Epoch 110/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.6215 - accuracy: 0.8692\n",
      "Epoch 111/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5983 - accuracy: 0.8773\n",
      "Epoch 112/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5753 - accuracy: 0.8791\n",
      "Epoch 113/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5858 - accuracy: 0.8820\n",
      "Epoch 114/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.5931 - accuracy: 0.8762\n",
      "Epoch 115/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.5557 - accuracy: 0.8870\n",
      "Epoch 116/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5698 - accuracy: 0.8764\n",
      "Epoch 117/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5738 - accuracy: 0.8802\n",
      "Epoch 118/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.5397 - accuracy: 0.8798\n",
      "Epoch 119/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.5126 - accuracy: 0.8958\n",
      "Epoch 120/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.5171 - accuracy: 0.8892\n",
      "Epoch 121/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.5318 - accuracy: 0.8806\n",
      "Epoch 122/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4820 - accuracy: 0.9023\n",
      "Epoch 123/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4918 - accuracy: 0.8987\n",
      "Epoch 124/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.5211 - accuracy: 0.8815\n",
      "Epoch 125/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4806 - accuracy: 0.8920\n",
      "Epoch 126/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.4835 - accuracy: 0.8898\n",
      "Epoch 127/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4991 - accuracy: 0.8870\n",
      "Epoch 128/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4418 - accuracy: 0.9070\n",
      "Epoch 129/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4684 - accuracy: 0.8935\n",
      "Epoch 130/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4588 - accuracy: 0.8923\n",
      "Epoch 131/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4511 - accuracy: 0.9009\n",
      "Epoch 132/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.4727 - accuracy: 0.8919\n",
      "Epoch 133/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4385 - accuracy: 0.9020\n",
      "Epoch 134/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4160 - accuracy: 0.9076\n",
      "Epoch 135/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4317 - accuracy: 0.8999\n",
      "Epoch 136/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4349 - accuracy: 0.8993\n",
      "Epoch 137/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4360 - accuracy: 0.9030\n",
      "Epoch 138/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4120 - accuracy: 0.9058\n",
      "Epoch 139/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4186 - accuracy: 0.9052\n",
      "Epoch 140/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3932 - accuracy: 0.9095\n",
      "Epoch 141/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4033 - accuracy: 0.9063\n",
      "Epoch 142/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3815 - accuracy: 0.9130\n",
      "Epoch 143/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3675 - accuracy: 0.9210\n",
      "Epoch 144/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.8987\n",
      "Epoch 145/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3897 - accuracy: 0.9080\n",
      "Epoch 146/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3876 - accuracy: 0.9061\n",
      "Epoch 147/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.9015\n",
      "Epoch 148/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3503 - accuracy: 0.9158\n",
      "Epoch 149/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3687 - accuracy: 0.9099\n",
      "Epoch 150/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3426 - accuracy: 0.9151\n",
      "Epoch 151/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.3976 - accuracy: 0.9051\n",
      "Epoch 152/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.3669 - accuracy: 0.9118\n",
      "Epoch 153/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.3434 - accuracy: 0.9165\n",
      "Epoch 154/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.3876 - accuracy: 0.9002\n",
      "Epoch 155/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.3762 - accuracy: 0.9060\n",
      "Epoch 156/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.3647 - accuracy: 0.9066\n",
      "Epoch 157/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.3459 - accuracy: 0.9101\n",
      "Epoch 158/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3342 - accuracy: 0.9285\n",
      "Epoch 159/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3098 - accuracy: 0.9225\n",
      "Epoch 160/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3228 - accuracy: 0.9128\n",
      "Epoch 161/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3290 - accuracy: 0.9190\n",
      "Epoch 162/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3182 - accuracy: 0.9165\n",
      "Epoch 163/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.3181 - accuracy: 0.9240\n",
      "Epoch 164/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3095 - accuracy: 0.9210\n",
      "Epoch 165/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3484 - accuracy: 0.9054\n",
      "Epoch 166/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3124 - accuracy: 0.9239\n",
      "Epoch 167/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.2886 - accuracy: 0.9275\n",
      "Epoch 168/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3060 - accuracy: 0.9185\n",
      "Epoch 169/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3043 - accuracy: 0.9168\n",
      "Epoch 170/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.3038 - accuracy: 0.9177\n",
      "Epoch 171/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.2985 - accuracy: 0.9182\n",
      "Epoch 172/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3086 - accuracy: 0.9126\n",
      "Epoch 173/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.2753 - accuracy: 0.9252\n",
      "Epoch 174/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.2753 - accuracy: 0.9238\n",
      "Epoch 175/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.3212 - accuracy: 0.9095\n",
      "Epoch 176/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.3049 - accuracy: 0.9146\n",
      "Epoch 177/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.2933 - accuracy: 0.9168\n",
      "Epoch 178/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.3052 - accuracy: 0.9202\n",
      "Epoch 179/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.2526 - accuracy: 0.9301\n",
      "Epoch 180/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.2627 - accuracy: 0.9277\n",
      "Epoch 181/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.2789 - accuracy: 0.9193\n",
      "Epoch 182/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.2685 - accuracy: 0.9203\n",
      "Epoch 183/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.2701 - accuracy: 0.9217\n",
      "Epoch 184/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.2873 - accuracy: 0.9162\n",
      "Epoch 185/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.2602 - accuracy: 0.9318\n",
      "Epoch 186/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.2699 - accuracy: 0.9218\n",
      "Epoch 187/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.2848 - accuracy: 0.9128\n",
      "Epoch 188/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.2662 - accuracy: 0.9304\n",
      "Epoch 189/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.2932 - accuracy: 0.9110\n",
      "Epoch 190/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.2768 - accuracy: 0.9242\n",
      "Epoch 191/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.2660 - accuracy: 0.9193\n",
      "Epoch 192/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.2752 - accuracy: 0.9169\n",
      "Epoch 193/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.2807 - accuracy: 0.9187\n",
      "Epoch 194/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.2849 - accuracy: 0.9140\n",
      "Epoch 195/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.2631 - accuracy: 0.9213\n",
      "Epoch 196/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.2407 - accuracy: 0.9298\n",
      "Epoch 197/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.2719 - accuracy: 0.9143\n",
      "Epoch 198/200\n",
      "61/61 [==============================] - 0s 5ms/step - loss: 0.2651 - accuracy: 0.9198\n",
      "Epoch 199/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.2490 - accuracy: 0.9236\n",
      "Epoch 200/200\n",
      "61/61 [==============================] - 0s 6ms/step - loss: 0.2316 - accuracy: 0.9266\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f332a7de790>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Embedding, Dense, LSTM\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "# y데이터를 분리하였으므로 이제 X데이터의 길이는 기존 데이터의 길이 - 1\n",
    "model.add(Embedding(vocab_size, 10, input_length=max_len-1))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, y, epochs=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9C7-QUKZUmP"
   },
   "source": [
    "### (실습) 문장을 생성하는 sentence_generation() 함수\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 575,
     "status": "ok",
     "timestamp": 1618534344259,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "2PxmkVdTZUmQ"
   },
   "outputs": [],
   "source": [
    "# 사용할 모델, 토크나이저, 현재 단어, 생성할 단어 수\n",
    "def sentence_generation(model, t, current_word, n): \n",
    "    init_word = current_word # 처음 들어온 단어도 마지막에 같이 출력하기 위해 저장\n",
    "    sentence = ''\n",
    "    for _ in range(n): # n번 반복\n",
    "        # 현재 단어에 대한 정수 인코딩\n",
    "        encoded = t.texts_to_sequences([current_word])[0] \n",
    "        #print(encoded)\n",
    "        # 데이터를 같은 길이로 맞춤 (pre : 앞 부분에 0을 추가, post : 뒷 부분에 0을 추가)\n",
    "        encoded = pad_sequences([encoded], maxlen=max_len-1, padding='pre') \n",
    "        # 입력한 X(현재 단어)에 대해서 y를 예측하고 y(예측한 단어)를 result에 저장.\n",
    "        result = model.predict_classes(encoded, verbose=0)        \n",
    "        \n",
    "        for word, index in t.word_index.items(): \n",
    "            # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
    "            # 해당 단어가 예측 단어이므로 break\n",
    "            if index == result: \n",
    "                break \n",
    "        # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경        \n",
    "        current_word = current_word + ' '  + word \n",
    "        # 예측 단어를 문장에 저장\n",
    "        sentence = sentence + ' ' + word \n",
    "\n",
    "    # 문장 생성\n",
    "    sentence = init_word + sentence\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2wdYjuuZUmR"
   },
   "source": [
    "### (실습)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 901,
     "status": "ok",
     "timestamp": 1618534347637,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "WvWyICdwZUmR",
    "outputId": "1ad57bd2-09db-476d-fd83-400270e53031"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미 대선 투표 율 사상 최대 되다 것 사전투표 참여 1억 명\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, '미 대선', 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5w2mOGzZUmT"
   },
   "source": [
    "### (실습) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 864,
     "status": "ok",
     "timestamp": 1618534352322,
     "user": {
      "displayName": "강성관",
      "photoUrl": "",
      "userId": "00571094306841577419"
     },
     "user_tz": -540
    },
    "id": "4KnWCRMjZUmU",
    "outputId": "0a7c1ae5-553a-4ba1-ba9c-f80eec79906a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "대주주 과세 뉴스 우편 투표 담기다 대선 결과 트럼프 바이든 승자 승자\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, tokenizer, '대주주 과세', 10))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DL021_RNN을 이용한 텍스트생성.ipynb",
   "provenance": [
    {
     "file_id": "1nZX_OEgr3KfLmu-EAbSBAdPjDY0NlDoN",
     "timestamp": 1568904334915
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
